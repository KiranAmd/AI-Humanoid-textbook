# Copilot Instructions — Physical AI Book Hackathon

This file explains repository-specific structure, conventions, and run/build workflows to help AI coding agents be immediately productive.

1. Big picture
- Frontend: Docusaurus static site at the repo root (see `package.json` and `README.md`). Use `yarn start` for dev and `yarn build` to produce `build/`.
- Backend: FastAPI app in the `backend/` folder. Key entry: `backend/main.py` (exports `handler` for Vercel and runs via `uvicorn` for local dev).
- Data & services: `backend/services/` contains integrations:
  - `gemini_service.py` — Google Generative AI (Gemini) wrapper (model: `gemini-2.5-flash`, embedding model: `models/text-embedding-005`).
  - `qdrant_service.py` — Qdrant vector store client using environment vars `QDRANT_URL` and `QDRANT_API_KEY` and collection `robotics_textbook`.
  - `database.py` — asyncpg Neon/Postgres helper using `DATABASE_URL`.

2. Important env vars
- `GEMINI_API_KEY` — required by `GeminiService` (raises if missing).
- `QDRANT_URL`, `QDRANT_API_KEY` — required by `QdrantService`.
- `DATABASE_URL` — required by `DatabaseService`.
- The backend loads `.env` via `python-dotenv` in `backend/`.

3. How the backend flows
- `POST /chat` (`backend/main.py`): accepts `ChatMessage` (see `backend/models/schemas.py`). If `selected_text` is provided it becomes the context and a source; otherwise a default textbook context is used. The request is forwarded to `GeminiService.generate_response(prompt, context)` and responded as `ChatResponse`.
- `POST /personalize`: builds a personalization prompt (see `main.py`), calls `gemini_service.model.generate_content(prompt)` and returns `personalizedContent`.
- `POST /translate`: builds a translation prompt (Urdu <> English) and uses `gemini_service.model.generate_content`.
- Vector operations: `GeminiService` creates embeddings via `embed_content` and `QdrantService` stores/searches them; use `generate_embeddings` / `generate_query_embedding` names in `gemini_service.py`.

4. Running & debugging
- Frontend (docs):
  - Dev: `yarn` then `yarn start` (see `package.json` and root `README.md`).
  - Build: `yarn build` → `build/`
- Backend (local):
  - From `backend/` install deps: `python -m pip install -r requirements.txt`.
  - Set `.env` with required keys and run: `cd backend && uvicorn main:app --reload --port 8000` or `python main.py`.
  - For Vercel deployment the FastAPI `handler = app` export is used.

5. Project-specific conventions & examples
- Working directory for backend commands: change into `backend/` first — imports in `main.py` use `from services...`.
- Pydantic models are small and explicit: `ChatMessage`, `ChatResponse`, `EmbedRequest` in `backend/models/schemas.py`.
- Gemini wrapper usage: call `self.model.generate_content(prompt)` and access `.text` on the response (see `gemini_service.py`).
- Embedding model: `models/text-embedding-005` is used with `genai.embed_content(..., task_type="retrieval_document"|"retrieval_query")`.
- Qdrant collection name is `robotics_textbook` (see `qdrant_service.py`).

6. Integration pitfalls to watch for
- Missing env vars will raise early: guard or mock them in unit tests.
- The backend assumes synchronous calls to `genai` (wrapper methods are synchronous). If converting to async, keep call sites consistent.
- When updating Gemini model names, update both the model creation and any comments documenting older names (see `gemini_service.py`).

7. Helpful examples to reference when editing code
- To change the chat prompt, update `full_prompt` inside `GeminiService.generate_response` in `backend/services/gemini_service.py`.
- To add vector search before generating answers, call `generate_query_embedding` then `QdrantService.search_similar(...)` and merge results into `context` in `backend/main.py`.

8. Where to look next
- Docs & site: `package.json`, `README.md`, `docs/` folder for content conventions.
- Backend entry & routes: `backend/main.py`.
- AI & infra: `backend/services/gemini_service.py`, `backend/services/qdrant_service.py`, `backend/services/database.py`.

If anything here is unclear or you'd like me to include more examples (e.g., sample `.env`, typical `curl` requests for the API, or a minimal unit test), tell me which section to expand and I'll iterate.
<!-- Short, actionable instructions for AI coding agents working on this repo -->
# Copilot instructions — Physical AI Textbook repo

This file contains focused, actionable guidance for AI coding assistants working in this repository.

1. Purpose
- Help maintain and extend a Docusaurus-based textbook plus a FastAPI backend that powers an embedding/search/chat pipeline.

2. Big-picture architecture
- Frontend: Docusaurus site in the repo root and `my-website/` (docs served from `/docs`). Sidebars are autogenerated by `my-website/sidebars.js`.
- Backend: `backend/` FastAPI service (`main.py`) exposing endpoints `/chat`, `/personalize`, `/translate`, and `/health`.
- Embedding pipeline: `backend/embed_content.py` reads Markdown from `../docs`, chunks text, uses `services/gemini_service.py` to generate embeddings and `services/qdrant_service.py` to store vectors in Qdrant.
- Persistence: `services/database.py` uses `asyncpg` to manage user/chat/document tables (Neon/Postgres-style `DATABASE_URL`).

3. Important files to inspect (examples)
- [backend/main.py](backend/main.py) — FastAPI routes and how context/sources are constructed.
- [backend/embed_content.py](backend/embed_content.py) — chunking logic (`chunk_size=1000`, `overlap=200`) and rate-limit handling.
- [backend/services/gemini_service.py](backend/services/gemini_service.py) — Gemini model names, embedding model, and methods used by other services.
- [backend/services/qdrant_service.py](backend/services/qdrant_service.py) — collection name `robotics_textbook`, vector size expectation (768) and add/search usage.
- [backend/services/database.py](backend/services/database.py) — table schemas and `initialize_tables()` used by embedding flow.
- [my-website/sidebars.js](my-website/sidebars.js) and [docusaurus.config.js](docusaurus.config.js) — docs organization and build/deploy settings.

4. Secrets & environment
- Required environment variables (place in `.env` for local dev): `GEMINI_API_KEY`, `QDRANT_URL`, `QDRANT_API_KEY`, `DATABASE_URL`.
- `backend/gemini_service.py` expects `GEMINI_API_KEY`; failing to set it raises an exception.

5. Developer workflows / commands
- Local site dev: run `yarn` then `yarn start` from repo root or `my-website/` (Docusaurus). Scripts in `package.json` (`start`, `build`, `deploy`).
- Backend dev: run `uvicorn main:app --reload` from `backend/` or `python backend/main.py` (the file runs uvicorn when executed). For Vercel, `main.handler` is exported.
- Generate embeddings: run `python backend/embed_content.py` (ensure `../docs` path is reachable from `backend/`, env vars set, and Qdrant reachable).

Local backend run steps
- Prerequisites:
  - Python 3.10+ installed and available on PATH.
  - Create and activate a virtual environment before installing packages (Windows `cmd` examples below).
  - Add a `.env` file to `backend/` with the required secrets:

```
GEMINI_API_KEY=<your_gemini_api_key>
QDRANT_URL=<https://your-qdrant-host>
QDRANT_API_KEY=<your_qdrant_api_key>
DATABASE_URL=postgresql://user:password@host:5432/database
```

- Install and run (Windows `cmd`):

```bat
python -m venv .venv
.venv\Scripts\activate
pip install -r backend/requirements.txt
pip install asyncpg    # required if using Postgres (database.py uses asyncpg)
```

- Start the backend (from `backend/`):

```bat
uvicorn main:app --reload --host 0.0.0.0 --port 8000
# or
python main.py
```

- Quick smoke tests:

```bat
curl http://localhost:8000/health
curl -X POST http://localhost:8000/chat -H "Content-Type: application/json" -d "{\"message\": \"Hello\"}"
```

- Notes:
  - `gemini_service.py` will raise if `GEMINI_API_KEY` is missing — verify `.env` or your shell env.
  - `embed_content.py` expects `../docs` relative to the `backend/` folder; run it from `backend/` or update the path.
  - If your `DATABASE_URL` points to Postgres/Neon, ensure `asyncpg` is installed and reachable.

6. Project-specific patterns & conventions
- Docs are the canonical content source: `embed_content.py` reads `../docs` (relative). When adding docs, expect to re-run the embed pipeline.
- Sidebars are autogenerated by default — avoid editing `sidebars.js` unless intentionally customizing order or categories.
- Embedding behavior: chunks are created with 1000-char windows and 200-char overlap. Rate-limiting is handled by sleeps in `embed_content.py` (simple throttling logic; keep or improve carefully).
- Vector collection: `robotics_textbook` must be used consistently; changing it requires reindexing Qdrant and updating calls in `qdrant_service.py`.

7. Integration points and external deps
- Gemini: `google.generativeai` used in `gemini_service.py` (model `gemini-2.5-flash` and embedding model `models/text-embedding-005`).
- Qdrant: `qdrant_client` used in `qdrant_service.py` (requires `QDRANT_URL` and `QDRANT_API_KEY`).
- Postgres: `asyncpg` for user/chat/document persistence (`DATABASE_URL`).
- Frontend build expects Node >=20 per `package.json` `engines` field.

8. What AI agents should (and should not) change
- SHOULD:
  - Fix small, well-scoped bugs in the backend and embedding pipeline that don't require secret access (e.g., improve error handling, adjust chunk logic, add logging).
  - Add or update docs in `docs/` and keep `embed_content.py` path in mind; suggest re-embedding after content changes.
  - Update model names in `gemini_service.py` only when validated; include fallback handling if env vars missing.
- SHOULD NOT:
  - Reorganize the Docusaurus docs structure without confirming impacts on `sidebars.js` autogeneration and the embedding pipeline.
  - Change the Qdrant collection name or vector dimensions without coordinating reindexing.

9. Quick examples to reference
- Chat request model: see `backend/models/schemas.py` (`ChatMessage` and `ChatResponse`) and the `/chat` handler in `backend/main.py`.
- Embedding flow: `embed_content.py` -> `gemini_service.generate_embeddings()` -> `qdrant_service.add_document()`.

10. When you finish a change
- Run `yarn start` to verify site rendering changes (docs). Run backend locally (`uvicorn`) to exercise API endpoints.
- If docs changed, recommend re-running `python backend/embed_content.py` (or document a CI job) to refresh embeddings.

Feedback
- If anything above is unclear or you'd like more detail about running the backend locally, tests, or CI, tell me which area to expand.
